{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq0NFqLlupHL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU3A9xJhvj2-",
        "outputId": "ef29ca91-72e1-47b4-f165-7e014920461b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Check if we're using GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UnneWxvvoGo"
      },
      "outputs": [],
      "source": [
        "# 2. Data Loading and Preparation\n",
        "# 2.1 Load Input Data\n",
        "# Load the data (modify paths as needed, data is shared here: https://drive.google.com/drive/u/0/folders/1ORxHegaYo2Clufvce78shuwMXyTt4epJ)\n",
        "hourly_data_csv = 'hourly_data.csv'\n",
        "hourly_ontario_csv = 'hourly_ontario_demand.csv'\n",
        "forecast_climate_csv = 'forecast_climate.csv'\n",
        "actual_toronto_demand_csv = 'actual_toronto_demand.csv'\n",
        "actual_ontario_demand_csv = 'actual_ontario_demand.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez9mycOkvukS"
      },
      "outputs": [],
      "source": [
        "hourly_data = pd.read_csv(hourly_data_csv)\n",
        "hourly_data['datetime'] = pd.to_datetime(hourly_data['datetime'])\n",
        "\n",
        "hourly_ontario = pd.read_csv(hourly_ontario_csv)\n",
        "hourly_ontario['datetime'] = pd.to_datetime(hourly_ontario['datetime'])\n",
        "\n",
        "forecast_climate = pd.read_csv(forecast_climate_csv)\n",
        "forecast_climate['datetime'] = pd.to_datetime(forecast_climate['datetime'])\n",
        "\n",
        "actual_toronto_demand = pd.read_csv(actual_toronto_demand_csv)\n",
        "actual_toronto_demand = actual_toronto_demand.rename(columns={\"Toronto\": 'actual'})\n",
        "actual_toronto_demand['datetime'] = pd.to_datetime(actual_toronto_demand['datetime'])\n",
        "\n",
        "actual_ontario_demand = pd.read_csv(actual_ontario_demand_csv)\n",
        "actual_ontario_demand['datetime'] = pd.to_datetime(actual_ontario_demand['datetime'])\n",
        "actual_ontario_demand = actual_ontario_demand.rename(columns={\"Ontario Demand\": 'actual'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPets3Xnv5GZ"
      },
      "outputs": [],
      "source": [
        "# 3. Dataset Definition\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for time series data\"\"\"\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        # Ensure targets have shape [n_samples, 1]\n",
        "        if len(targets.shape) == 1:\n",
        "            targets = targets.reshape(-1, 1)\n",
        "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYM5qVEiv5r5"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, embed_dim)\n",
        "        attn_output, _ = self.multihead_attn(x, x, x)\n",
        "        return attn_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbSMFKUFwZQk"
      },
      "outputs": [],
      "source": [
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_dim=128, lstm_layers=2, dropout=0.3, output_shape=1):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.seq_length, self.n_features = input_shape\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # LSTM layers for sequence processing\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.n_features,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = MultiHeadSelfAttention(embed_dim=hidden_dim, num_heads=4)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Global pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 64)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.fc3 = nn.Linear(64, output_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_length, n_features)\n",
        "\n",
        "        # LSTM layers\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        # lstm_out shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_output = self.attention(lstm_out)\n",
        "\n",
        "        # Skip connection and layer normalization\n",
        "        x = lstm_out + attn_output\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        # Global average pooling across sequence dimension\n",
        "        x = x.transpose(1, 2)  # Shape: (batch_size, hidden_dim, seq_length)\n",
        "        x = self.global_avg_pool(x).squeeze(-1)  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # Reshape to ensure output has shape [batch_size, 1]\n",
        "        x = x.view(-1, 1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wppvsuQcwcXs"
      },
      "outputs": [],
      "source": [
        "# 6. Data Processing and Model Training Functions\n",
        "# 6.1 Data Preparation Functions\n",
        "def prepare_data_for_model(region, data, target_column, window_size=168, forecast_horizon=1):\n",
        "    \"\"\"Prepare time series data for the LSTM-Attention model\"\"\"\n",
        "    \n",
        "     # Extract target variable\n",
        "    y_values = data[target_column].values\n",
        "\n",
        "    # Get all feature columns (excluding target and datetime columns)\n",
        "    exclude_cols = ['datetime', 'date', target_column, 'region']\n",
        "    # Select only numeric columns\n",
        "    numeric_columns = data.select_dtypes(include=['number']).columns\n",
        "    feature_columns = [col for col in numeric_columns if col not in exclude_cols]\n",
        "    print(f\"Feature columns count: {len(feature_columns)}\")\n",
        "\n",
        "    num_sliding_windows = len(data) - window_size - forecast_horizon + 1\n",
        "    print(f\"Number of sliding windows: {num_sliding_windows}\")\n",
        "\n",
        "    report_frequency = max(1, num_sliding_windows // 20)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create sequences using sliding window approach\n",
        "    X, y = [], []\n",
        "    for i in range(num_sliding_windows):\n",
        "        # Extract the window of features\n",
        "        features = data[feature_columns].iloc[i:(i+window_size)].values\n",
        "\n",
        "        # Extract the target value(s) to predict\n",
        "        target = y_values[i + window_size:i + window_size + forecast_horizon]\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(target)\n",
        "\n",
        "        # Report progress\n",
        "        if i % report_frequency == 0:\n",
        "            percentage = round((i / num_sliding_windows) * 100, 2)\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print(f\"Processed {i}/{num_sliding_windows} windows, ({percentage}%) in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f\"Data preparation complete: X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scale_features(X, y):\n",
        "  \"\"\"Scale features and targets using StandardScaler\"\"\"\n",
        "  # Scale features\n",
        "  n_samples, n_timesteps, n_features = X.shape\n",
        "  X_reshaped = X.reshape(n_samples * n_timesteps, n_features)\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_X.fit(X_reshaped)\n",
        "  X_scaled = scaler_X.transform(X_reshaped).reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "  scaler_y = StandardScaler()\n",
        "  scaler_y.fit(y)\n",
        "  y_scaled = scaler_y.transform(y).flatten()\n",
        "\n",
        "  return X_scaled, y_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14H8QZqixTQX"
      },
      "source": [
        "# 6.2 Model Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uLtbQiNxQf7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, loader, device,\n",
        "               epochs=50, learning_rate=0.001, model_save_path='best_lstm_model.pth'):\n",
        "    \"\"\"Train the PyTorch model with early stopping\"\"\"\n",
        "    # Move model to device (GPU if available)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # For tracking metrics\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'mae': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        losses = []\n",
        "        maes = []\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
        "\n",
        "        # Training loop\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Ensure targets have the right shape [batch_size, 1]\n",
        "            if len(targets.shape) == 1:\n",
        "                targets = targets.view(-1, 1)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Record metrics\n",
        "            losses.append(loss.item())\n",
        "            mae = torch.mean(torch.abs(outputs - targets)).item()\n",
        "            maes.append(mae)\n",
        "\n",
        "        # Calculate average metrics for the epoch\n",
        "        avg_loss = np.mean(losses)\n",
        "        avg_mae = np.mean(maes)\n",
        "\n",
        "        # Update history\n",
        "        history['loss'].append(avg_loss)\n",
        "        history['mae'].append(avg_mae)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"  Loss: {avg_loss:.4f} - MAE: {avg_mae:.4f}\")\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JobvDN9-xWxE"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(region, frequency, model, test_loader, device, scaler_y=None):\n",
        "    \"\"\"Evaluate model performance on test set\"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            # Move data to device\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Move predictions back to CPU\n",
        "            outputs = outputs.cpu().numpy()\n",
        "            targets = targets.numpy()\n",
        "\n",
        "            all_preds.extend(outputs)\n",
        "            all_targets.extend(targets)\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    y_pred = np.array(all_preds)\n",
        "    y_test = np.array(all_targets)\n",
        "\n",
        "    # Inverse transform predictions and actual values\n",
        "    if scaler_y is not None:\n",
        "        # Reshape if needed\n",
        "        y_pred_reshaped = y_pred.reshape(-1, 1)\n",
        "        y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_reshaped).flatten()\n",
        "        y_test = scaler_y.inverse_transform(y_test_reshaped).flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = np.mean(np.abs(y_test - y_pred))\n",
        "    rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "    print(f\"Test MAE: {mae:.2f}\")\n",
        "    print(f\"Test RMSE: {rmse:.2f}\")\n",
        "    print(f\"Test MAPE: {mape:.2f}%\")\n",
        "\n",
        "    # Plot actual vs predicted\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_test[:100], label='Actual')\n",
        "    plt.plot(y_pred[:100], label='Predicted')\n",
        "    plt.legend()\n",
        "    plt.title(f'Actual vs Predicted Energy Demand for {region}')\n",
        "    plt.ylabel('Energy Demand')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/lstm_actual_vs_predicted_{region}.png')\n",
        "    plt.close()\n",
        "\n",
        "    return mae, rmse, mape, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mqIT9CnxZow"
      },
      "source": [
        "# 7. Forecasting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4z5N2CqxadK"
      },
      "outputs": [],
      "source": [
        "def recursive_forecast_without_weather(model, initial_input, scaler_X, scaler_y, n_steps=168):\n",
        "    \"\"\"Make recursive forecasts without using weather data.\n",
        "\n",
        "    Args:\n",
        "        model: Trained LSTM-Attention model\n",
        "        initial_input: Last window of historical data\n",
        "        scaler_X: Feature scaler\n",
        "        scaler_y: Target scaler\n",
        "        n_steps: Number of future steps to predict\n",
        "\n",
        "    Returns:\n",
        "        Numpy array of predictions\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Scale the initial input\n",
        "    n_samples, n_timesteps, n_features = initial_input.shape\n",
        "    X_reshaped = initial_input.reshape(n_samples * n_timesteps, n_features)\n",
        "    X_scaled = scaler_X.transform(X_reshaped).reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "    # Convert to tensor\n",
        "    current_input = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Storage for predictions\n",
        "    predictions = []\n",
        "\n",
        "    # Make a copy of the input that we'll update\n",
        "    forecast_input = current_input.clone()\n",
        "    \n",
        "    print(\"Sample values from first timestep:\")\n",
        "    print(forecast_input[0, 0, :].cpu().numpy())\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_steps):\n",
        "            # Make one-step prediction\n",
        "            output = model(forecast_input)\n",
        "\n",
        "            # Convert prediction back to CPU and numpy\n",
        "            pred = output.cpu().numpy()[0, 0]\n",
        "            predictions.append(pred)\n",
        "\n",
        "            # Create a new timestep by copying the most recent one and update with prediction\n",
        "            new_timestep = forecast_input[:, -1:, :].clone()\n",
        "\n",
        "            # Find the feature index that corresponds to the target value\n",
        "            demand_indices = 0\n",
        "\n",
        "            # If no demand indices found, use the first index as default\n",
        "            target_idx = demand_indices[0] if demand_indices else 0\n",
        "\n",
        "            # Update the demand feature with our prediction\n",
        "            new_timestep[0, 0, target_idx] = torch.tensor(pred, dtype=torch.float32).to(device)\n",
        "\n",
        "            # Shift window and add new timestep\n",
        "            forecast_input = torch.cat([\n",
        "                forecast_input[:, 1:, :],  # Remove oldest timestep\n",
        "                new_timestep  # Add new timestep\n",
        "            ], dim=1)\n",
        "\n",
        "    # Inverse transform the predictions\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    predictions = scaler_y.inverse_transform(predictions).flatten()\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def recursive_forecast_with_weather(model, initial_input, scaler_X, scaler_y, feature_columns,\n",
        "                                  forecast_weather, n_steps=168):\n",
        "  \"\"\"Make recursive forecasts using forecasted weather data.\n",
        "\n",
        "  Args:\n",
        "      model: Trained LSTM-Attention model\n",
        "      initial_input: Last window of historical data\n",
        "      scaler_X: Feature scaler\n",
        "      scaler_y: Target scaler\n",
        "      feature_columns: List of feature names\n",
        "      forecast_weather: DataFrame with forecasted weather\n",
        "      n_steps: Number of future steps to predict\n",
        "\n",
        "  Returns:\n",
        "      Numpy array of predictions\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  # Scale the initial input\n",
        "  n_samples, n_timesteps, n_features = initial_input.shape\n",
        "  X_reshaped = initial_input.reshape(n_samples * n_timesteps, n_features)\n",
        "  X_scaled = scaler_X.transform(X_reshaped).reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "  # Convert to tensor\n",
        "  current_input = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "  # Storage for predictions\n",
        "  predictions = []\n",
        "\n",
        "  # Make a copy of the input that we'll update\n",
        "  forecast_input = current_input.clone()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for i in range(n_steps):\n",
        "          # Make one-step prediction\n",
        "          output = model(forecast_input)\n",
        "\n",
        "          # Convert prediction back to CPU and numpy\n",
        "          pred = output.cpu().numpy()[0, 0]\n",
        "          predictions.append(pred)\n",
        "\n",
        "          # Create a new tensor for the next timestep\n",
        "          new_timestep = torch.zeros(1, 1, n_features).to(device)\n",
        "\n",
        "          # Get the weather data for this timestep\n",
        "          weather_data = forecast_weather.iloc[i].copy()\n",
        "\n",
        "          # Create array to hold new feature values\n",
        "          new_features = np.zeros(n_features)\n",
        "\n",
        "          # Fill in feature values based on weather and predicted demand\n",
        "          for j, feature_name in enumerate(feature_columns):\n",
        "              if feature_name in weather_data.index:\n",
        "                  # This is a weather feature\n",
        "                  new_features[j] = weather_data[feature_name]\n",
        "              elif 'demand' in feature_name.lower():\n",
        "                  # This is a demand feature, use the prediction\n",
        "                  if '_lag_' in feature_name:\n",
        "                      # This is a lagged demand feature, handle according to lag\n",
        "                      lag = int(feature_name.split('_lag_')[1])\n",
        "                      if i >= lag:\n",
        "                          # Use an earlier prediction\n",
        "                          new_features[j] = predictions[i - lag]\n",
        "                      else:\n",
        "                          # Use the initial input data for earlier lags\n",
        "                          orig_idx = n_timesteps - lag + i\n",
        "                          if orig_idx >= 0:\n",
        "                              demand_idx = j % n_features\n",
        "                              new_features[j] = initial_input[0, orig_idx, demand_idx]\n",
        "                  else:\n",
        "                      # Current demand\n",
        "                      new_features[j] = pred\n",
        "              elif 'day_of_week' in feature_name:\n",
        "                  # Calculate day of week\n",
        "                  new_features[j] = (forecast_weather.iloc[i]['day_of_week'])\n",
        "              elif 'month' in feature_name:\n",
        "                  # Month\n",
        "                  new_features[j] = (forecast_weather.iloc[i]['month'])\n",
        "              elif 'day_of_year' in feature_name:\n",
        "                  # Day of year\n",
        "                  new_features[j] = (forecast_weather.iloc[i]['day_of_year'])\n",
        "              elif 'is_holiday' in feature_name:\n",
        "                  # Holiday flag\n",
        "                  new_features[j] = (forecast_weather.iloc[i]['is_holiday'])\n",
        "              elif 'is_weekend' in feature_name:\n",
        "                  # Weekend flag\n",
        "                  new_features[j] = (forecast_weather.iloc[i]['is_weekend'])\n",
        "\n",
        "          # Scale the new features\n",
        "          new_features_scaled = scaler_X.transform(new_features.reshape(1, -1))\n",
        "\n",
        "          # Update the new timestep tensor\n",
        "          new_timestep[0, 0, :] = torch.tensor(new_features_scaled.flatten(), dtype=torch.float32).to(device)\n",
        "\n",
        "          # Shift window and add new timestep\n",
        "          forecast_input = torch.cat([\n",
        "              forecast_input[:, 1:, :],  # Remove oldest timestep\n",
        "              new_timestep  # Add new timestep\n",
        "          ], dim=1)\n",
        "\n",
        "  # Inverse transform the predictions\n",
        "  predictions = np.array(predictions).reshape(-1, 1)\n",
        "  predictions = scaler_y.inverse_transform(predictions).flatten()\n",
        "\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJehF929xwDm"
      },
      "source": [
        "# 8. Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOIB9sxpxy_d"
      },
      "outputs": [],
      "source": [
        "def forecast_energy_demand(region, region_data, target_column, window_size,\n",
        "                           epochs, batch_size, model, scaler_X, scaler_y,\n",
        "                           feature_columns, use_weather=True):\n",
        "    \"\"\"Main function to forecast energy demand\"\"\"\n",
        "    print(f\"Forecasting energy demand for {region}...\")\n",
        "\n",
        "    # Get the last window from historical data for initial forecast input\n",
        "    last_window_data = region_data.iloc[-window_size:].copy()\n",
        "\n",
        "    last_date = region_data['datetime'].iloc[-1]\n",
        "    print(f\"Last date in historical data: {last_date}\")\n",
        "    print(f\"First date in forecast period: {forecast_climate['datetime'].iloc[0]}\")\n",
        "\n",
        "    # Extract features for the last window\n",
        "    exclude_cols = ['datetime', 'date', target_column, 'region']\n",
        "    numeric_columns = region_data.select_dtypes(include=['number']).columns\n",
        "    feature_columns = [col for col in numeric_columns if col not in exclude_cols]\n",
        "    X = last_window_data[feature_columns].values.reshape(1, window_size, len(feature_columns))\n",
        "\n",
        "    # Make recursive forecasts\n",
        "    n_forecast_hours = 168  # One week\n",
        "\n",
        "    # if use_weather and region == \"Toronto\":\n",
        "    if use_weather:\n",
        "        print(\"Using weather data for forecasting...\")\n",
        "        predictions = recursive_forecast_with_weather(\n",
        "            model, X, scaler_X, scaler_y, feature_columns,\n",
        "            forecast_climate, n_steps=n_forecast_hours\n",
        "        )\n",
        "    else:\n",
        "        print(\"Not using weather data for forecasting...\")\n",
        "        predictions = recursive_forecast_without_weather(\n",
        "            model, X, scaler_X, scaler_y, n_steps=n_forecast_hours\n",
        "        )\n",
        "\n",
        "    # Create forecast dates\n",
        "    forecast_dates = [last_date + timedelta(hours=i+1) for i in range(n_forecast_hours)]\n",
        "\n",
        "    # Create forecast DataFrame\n",
        "    forecast_df = pd.DataFrame({\n",
        "        'datetime': forecast_dates,\n",
        "        'forecast': predictions,\n",
        "        'region': region\n",
        "    })\n",
        "\n",
        "    # Merge with actual demand for evaluation if available\n",
        "    try:\n",
        "        if region == \"Toronto\":\n",
        "            eval_df = pd.merge(\n",
        "                forecast_df,\n",
        "                actual_toronto_demand[['datetime', \"actual\"]],\n",
        "                on='datetime',\n",
        "                how='inner'\n",
        "            )\n",
        "        else:\n",
        "            eval_df = pd.merge(\n",
        "                forecast_df,\n",
        "                actual_ontario_demand[['datetime', \"actual\"]],\n",
        "                on='datetime',\n",
        "                how='inner'\n",
        "            )\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        mae = np.mean(np.abs(eval_df['actual'] - eval_df['forecast']))\n",
        "        rmse = np.sqrt(np.mean((eval_df['actual'] - eval_df['forecast'])**2))\n",
        "        mape = np.mean(np.abs((eval_df['actual'] - eval_df['forecast']) / eval_df['actual'])) * 100\n",
        "\n",
        "        print(f\"Evaluation Results for {region}:\")\n",
        "        print(f\"MAE: {mae:.2f}\")\n",
        "        print(f\"RMSE: {rmse:.2f}\")\n",
        "        print(f\"MAPE: {mape:.2f}%\")\n",
        "\n",
        "        # Plot forecasts vs actual\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot historical data\n",
        "        historical_dates = region_data['datetime'].iloc[-168:].values\n",
        "        historical_values = region_data[target_column].iloc[-168:].values\n",
        "        plt.plot(historical_dates, historical_values, label='Historical', color='blue')\n",
        "\n",
        "        # Plot forecasted data\n",
        "        plt.plot(eval_df['datetime'], eval_df['forecast'], label='LSTM-Attention Forecast', color='red')\n",
        "\n",
        "        # Plot actual data\n",
        "        plt.plot(eval_df['datetime'], eval_df['actual'], label='Actual', color='green')\n",
        "\n",
        "        weather_text = \"with weather\" if use_weather else \"without weather\"\n",
        "        plt.title(f'Energy Demand Forecast vs Actual for {region} ({weather_text})\\nMAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Energy Demand')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot\n",
        "        weather_label = \"with_weather\" if use_weather else \"without_weather\"\n",
        "        plt.savefig(f'results/lstm_{region}_{weather_label}_forecast_vs_actual.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results = pd.DataFrame({'MAE': [mae], \"RMSE\": [rmse], \"MAPE\": [mape]})\n",
        "        results.to_csv(f'results/lstm_{region}_{weather_label}_metrics.csv', index=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not perform evaluation against actual data: {e}\")\n",
        "        eval_df = None\n",
        "\n",
        "    # Save forecast DataFrame\n",
        "    weather_label = \"with_weather\" if use_weather else \"without_weather\"\n",
        "    forecast_df.to_csv(f'results/lstm_{region}_{weather_label}_forecast.csv', index=False)\n",
        "\n",
        "    print(f\"Forecast complete for {region}.\")\n",
        "\n",
        "    return forecast_df, model, scaler_X, scaler_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv_AR_xjx5SD"
      },
      "source": [
        "# 9. Model Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMM4ahnwVcov",
        "outputId": "7b136176-ab35-4840-caf5-f5f3195829a5"
      },
      "outputs": [],
      "source": [
        "# Parameters for the model\n",
        "region = \"Ontario\"\n",
        "window_size = 168  # One week of hourly data\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "target_column = 'zonal_demand' # what we are aiming to predict, for toronto it's zonal_demand\n",
        "\n",
        "# Create directories for results\n",
        "os.makedirs('results', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Run forecast \n",
        "print(\"Starting energy demand forecast\")\n",
        "data = hourly_ontario.copy() # substitute with toronto data here depending on what you're looking to run\n",
        "\n",
        "# we should split up training and the other steps, or else we're going to run into the same compute\n",
        "# issues as before\n",
        "model_save_path = f\"models/lstm_{region}_model.pth\"\n",
        "# Create cache directory if it doesn't exist\n",
        "os.makedirs(\"cache\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Prepare data\n",
        "X, y = prepare_data_for_model(region, data, target_column, window_size)\n",
        "\n",
        "# Scale features\n",
        "n_samples, n_timesteps, n_features = X.shape\n",
        "X_reshaped = X.reshape(n_samples * n_timesteps, n_features)\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "scaler_X.fit(X_reshaped)\n",
        "X_scaled = scaler_X.transform(X_reshaped).reshape(n_samples, n_timesteps, n_features)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "scaler_y.fit(y)\n",
        "y_scaled = scaler_y.transform(y).flatten()\n",
        "\n",
        "# Create dataloaders\n",
        "dataset = TimeSeriesDataset(X_scaled, y_scaled)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxIZWnrQUHZm",
        "outputId": "1a7d4e4a-eead-4bb5-a3bf-576a6bc1e343"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "input_shape = (X_scaled.shape[1], X_scaled.shape[2])  # (timesteps, features)\n",
        "model = LSTMAttentionModel(\n",
        "    input_shape=input_shape,\n",
        "    hidden_dim=128,\n",
        "    lstm_layers=2,\n",
        "    dropout=0.3\n",
        ")\n",
        "\n",
        "# Train model\n",
        "print(f\"Training LSTM-Attention model for {region}...\")\n",
        "model, history = train_model(\n",
        "    model,\n",
        "    loader,\n",
        "    device,\n",
        "    epochs=50,\n",
        "    learning_rate=0.001,\n",
        "    model_save_path=model_save_path\n",
        ")\n",
        "\n",
        "exclude_cols = ['datetime', 'date', target_column, 'region']\n",
        "numeric_columns = data.select_dtypes(include=['number']).columns\n",
        "feature_columns = [col for col in numeric_columns if col not in exclude_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EI60Zi_Qxhw",
        "outputId": "f2e27677-720b-47fa-daea-efac49033ddb"
      },
      "outputs": [],
      "source": [
        "ontario_forecast_with_weather, ontario_model, ontario_scaler_X, ontario_scaler_y = forecast_energy_demand(\n",
        "    region='Ontario',\n",
        "    region_data=data,\n",
        "    target_column=target_column_ontario,\n",
        "    window_size=window_size,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    scaler_X=scaler_X,\n",
        "    scaler_y=scaler_y,\n",
        "    feature_columns=feature_columns,\n",
        "    use_weather=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVA_WHtZkzFE",
        "outputId": "830f2569-8b59-4228-e51c-33757600162c"
      },
      "outputs": [],
      "source": [
        "ontario_forecast_with_weather, ontario_model, ontario_scaler_X, ontario_scaler_y = forecast_energy_demand(\n",
        "    region='Ontario',\n",
        "    region_data=data,\n",
        "    target_column=target_column,\n",
        "    window_size=window_size,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    scaler_X=scaler_X,\n",
        "    scaler_y=scaler_y,\n",
        "    feature_columns=feature_columns,\n",
        "    use_weather=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOSQhQ9Q6KU"
      },
      "source": [
        "# 11. Visualize Predicted vs. Actual Demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "JacavlXoWRa3",
        "outputId": "d873cad9-ce78-4fe0-a3f2-edb271e081e8"
      },
      "outputs": [],
      "source": [
        "# Create combined visualization of all predictions vs actual\n",
        "try:\n",
        "    # Read the prediction results\n",
        "    ontario_with_weather = pd.read_csv('results/lstm_Ontario_with_weather_forecast.csv')\n",
        "    ontario_without_weather = pd.read_csv('results/lstm_Ontario_without_weather_forecast.csv')\n",
        "\n",
        "    # Convert datetime columns\n",
        "    ontario_with_weather['datetime'] = pd.to_datetime(ontario_with_weather['datetime'])\n",
        "    ontario_without_weather['datetime'] = pd.to_datetime(ontario_without_weather['datetime'])\n",
        "\n",
        "    # Prepare actual data\n",
        "    actual_ontario = actual_ontario_demand.copy()\n",
        "    actual_ontario['datetime'] = pd.to_datetime(actual_ontario['datetime'])\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Toronto plot\n",
        "    # plt.subplot(2, 1, 1)\n",
        "    plt.plot(ontario_with_weather['datetime'], ontario_with_weather['forecast'],\n",
        "             label='LSTM-Attention predictions with weather forecast', color='red')\n",
        "    plt.plot(ontario_without_weather['datetime'], ontario_without_weather['forecast'],\n",
        "             label='LSTM-Attention without weather forecast', color='blue', linestyle='--')\n",
        "    plt.plot(actual_ontario['datetime'], actual_ontario['actual'],\n",
        "             label='Actual demand', color='green')\n",
        "\n",
        "    plt.title('Ontario Energy Demand Forecasting Comparison')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Energy Demand')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.savefig('results/lstm_combined_forecast_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not create visualization: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
